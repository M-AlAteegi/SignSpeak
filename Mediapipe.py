"""
Mediapipe.py
------------
Handles hand gesture detection and classification.

Features:
- Uses Mediapipe to extract hand landmarks from webcam frames.
- Loads a pre-trained MLP model to classify gestures into ASL letters.
- Applies saved label encoder and scaler for consistent preprocessing.
- Provides `detect_and_draw(frame)` to be called by the GUI.

Requirements:
- Requires 'asl_mlp_model_new.h5', 'label_encoder.pkl', and 'scaler.pkl' in /models.
- These files are generated by running Modeltraining.py.
"""

import cv2
import mediapipe as mp
import numpy as np
import tensorflow as tf
import pickle
import os
from sklearn.preprocessing import MinMaxScaler

# ─── Load Trained Model ────────────────────────────────────────────────
if not os.path.exists("models/asl_mlp_model_new.h5"):
    raise RuntimeError(
        "ASL model not found. Please run Modeltraining.py first to generate 'asl_mlp_model_new.h5'."
    )

model = tf.keras.models.load_model("models/asl_mlp_model_new.h5")
model.compile(optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"])

# ─── Load Label Encoder ────────────────────────────────────────────────
if not os.path.exists("models/label_encoder.pkl"):
    raise RuntimeError(
        "Label encoder not found. Please run Modeltraining.py first to generate 'label_encoder.pkl'."
    )

with open("models/label_encoder.pkl", "rb") as f:
    label_encoder = pickle.load(f)

if os.path.exists("models/scaler.pkl"):
    with open("models/scaler.pkl", "rb") as f:
        scaler = pickle.load(f)
else:
    raise RuntimeError(
        "Scaler not found. Please run Modeltraining.py first to generate 'scaler.pkl'."
    )

mp_hands = mp.solutions.hands
hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.5)
mp_draw = mp.solutions.drawing_utils

def detect_and_draw(frame):
    """Returns the frame with landmarks drawn and predicted letter"""
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    result = hands.process(frame_rgb)
    predicted_label = None

    if result.multi_hand_landmarks:
        for hand_landmarks in result.multi_hand_landmarks:
            mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

            # Extract landmarks
            landmarks = []
            for lm in hand_landmarks.landmark:
                landmarks.append(lm.x)
                landmarks.append(lm.y)

            landmarks = np.array(landmarks).reshape(1, -1)
            landmarks = scaler.transform(landmarks)
            prediction = model.predict(landmarks)
            predicted_index = np.argmax(prediction)

            if predicted_index < len(label_encoder.classes_):
                predicted_label = label_encoder.inverse_transform([predicted_index])[0]

    return frame, predicted_label
